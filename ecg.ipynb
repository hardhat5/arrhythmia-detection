{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import scipy.io\n",
    "\n",
    "import matplotlib.pyplot\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing the dataset\n",
    "\n",
    "data = scipy.io.loadmat('D:/Sahil/Projects/swd/NNFL/Assignment 3/data.mat')\n",
    "data = np.array(data['ecg_in_window'])\n",
    "data = data/np.max(data)\n",
    "\n",
    "labels = scipy.io.loadmat('D:/Sahil/Projects/swd/NNFL/Assignment 3/labels.mat')\n",
    "labels = np.array(labels['label'])\n",
    "\n",
    "final_data = np.zeros([1000, 1001])\n",
    "\n",
    "for i in range(1000):\n",
    "    final_data[:,i] = data[:,i]\n",
    "\n",
    "final_data[:,-1] = labels[:,-1]\n",
    "\n",
    "np.random.shuffle(final_data)\n",
    "\n",
    "final_data = np.array([final_data])\n",
    "final_data = np.reshape(final_data, (1000,1001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1107,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = final_data[:int(0.7*len(final_data))], final_data[int(0.7*len(final_data)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loader\n",
    "class SignalsDataset(Dataset):\n",
    "\n",
    "    def __init__(self, data, transform=None):\n",
    "        self.dataframe = data\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        sample = {}\n",
    "        \n",
    "        sample['data'] = np.reshape(self.dataframe[idx,:1000], (1, 1000))\n",
    "        sample['target'] = np.array(self.dataframe[idx,1000])\n",
    "        \n",
    "        sample['data'] = torch.from_numpy(sample['data'])\n",
    "        sample['target'] = torch.from_numpy(sample['target'])\n",
    "        \n",
    "        if self.transform:\n",
    "            sample = self.transform(np.array([sample]))\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1109,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1110,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_obj = SignalsDataset(data=train_data)\n",
    "test_data_obj = SignalsDataset(data=test_data)\n",
    "\n",
    "train_loader = DataLoader(train_data_obj, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "test_loader = DataLoader(test_data_obj, batch_size=batch_size, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1111,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.cnn_layers = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=1, out_channels=64, kernel_size=6, stride=1),\n",
    "            nn.AvgPool1d(kernel_size=2, stride=2),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3, stride=1),\n",
    "            nn.AvgPool1d(kernel_size=2, stride=2),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU())\n",
    "        \n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Linear(31616, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 1),\n",
    "            nn.Sigmoid())\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.cnn_layers(x)\n",
    "        x = x.view(x.size(0), -1) \n",
    "        x = self.linear(x)\n",
    "        x = torch.squeeze(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (cnn_layers): Sequential(\n",
      "    (0): Conv1d(1, 64, kernel_size=(6,), stride=(1,))\n",
      "    (1): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))\n",
      "    (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): ReLU()\n",
      "    (4): Conv1d(64, 128, kernel_size=(3,), stride=(1,))\n",
      "    (5): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))\n",
      "    (6): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): ReLU()\n",
      "  )\n",
      "  (linear): Sequential(\n",
      "    (0): Linear(in_features=31616, out_features=1024, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=1, bias=True)\n",
      "    (5): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = Net()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "criterion = nn.MSELoss()\n",
    "model = model.to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    \n",
    "    for i, sample in enumerate(train_loader):\n",
    "        data = sample['data'].to(device)\n",
    "        target = sample['target'].to(device) \n",
    "        data = data.float()\n",
    "        target = target.float()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        \n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "    print(\"Training epoch {}\".format(epoch+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing function\n",
    "def test():\n",
    "        \n",
    "        model.eval()\n",
    "        \n",
    "        test_loss = 0\n",
    "        correct = 0\n",
    "        \n",
    "        for i, sample in enumerate(test_loader):\n",
    "\n",
    "            data = sample['data'].to(device)\n",
    "            target = sample['target'].to(device) \n",
    "            data = data.float()\n",
    "            target = target.float()\n",
    "            \n",
    "            output = model(data)\n",
    "            \n",
    "            for j in range(len(target)):\n",
    "                out = 0 if output[j].item() < 0.5 else 1\n",
    "#                 print(out, target[j].item())\n",
    "                if target[j].item() == out:\n",
    "                    correct += 1\n",
    "        \n",
    "        print(\"Validation accuracy: \", correct/len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 1\n",
      "Validation accuracy:  0.6633333333333333\n",
      "Training epoch 2\n",
      "Validation accuracy:  0.7466666666666667\n",
      "Training epoch 3\n",
      "Validation accuracy:  0.7933333333333333\n",
      "Training epoch 4\n",
      "Validation accuracy:  0.7866666666666666\n",
      "Training epoch 5\n",
      "Validation accuracy:  0.7933333333333333\n",
      "Training epoch 6\n",
      "Validation accuracy:  0.8066666666666666\n",
      "Training epoch 7\n",
      "Validation accuracy:  0.8333333333333334\n",
      "Training epoch 8\n",
      "Validation accuracy:  0.8066666666666666\n",
      "Training epoch 9\n",
      "Validation accuracy:  0.8133333333333334\n",
      "Training epoch 10\n",
      "Validation accuracy:  0.8133333333333334\n",
      "Training epoch 11\n",
      "Validation accuracy:  0.8033333333333333\n",
      "Training epoch 12\n",
      "Validation accuracy:  0.82\n",
      "Training epoch 13\n",
      "Validation accuracy:  0.8\n",
      "Training epoch 14\n",
      "Validation accuracy:  0.83\n",
      "Training epoch 15\n",
      "Validation accuracy:  0.8166666666666667\n",
      "Training epoch 16\n",
      "Validation accuracy:  0.7833333333333333\n",
      "Training epoch 17\n",
      "Validation accuracy:  0.8033333333333333\n",
      "Training epoch 18\n",
      "Validation accuracy:  0.8033333333333333\n",
      "Training epoch 19\n",
      "Validation accuracy:  0.8066666666666666\n",
      "Training epoch 20\n",
      "Validation accuracy:  0.8033333333333333\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(20):\n",
    "    train(epoch)\n",
    "    with torch.no_grad():\n",
    "        test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
